{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Automatic scoring of x-ray images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# PIL to open & manipulate images\n",
    "from PIL import Image, ImageOps, ImageChops\n",
    "\n",
    "# for messages in loops\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# to save arrays\n",
    "import h5py\n",
    "\n",
    "# for folder-timestamp\n",
    "from datetime import datetime\n",
    "\n",
    "# for train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# for one-hot encoding\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "# for class weights\n",
    "from sklearn.utils import class_weight\n",
    "# for model evaluation\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# for efficient loops\n",
    "import itertools\n",
    "\n",
    "# keras\n",
    "from tensorflow.contrib.keras.python.keras import backend as K\n",
    "from tensorflow.contrib.keras.python.keras.utils.io_utils import HDF5Matrix\n",
    "from tensorflow.contrib.keras.python.keras.models import Sequential\n",
    "from tensorflow.contrib.keras.python.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Lambda, Activation\n",
    "from tensorflow.contrib.keras.python.keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.contrib.keras.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.contrib.keras.python.keras import callbacks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define image format & random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# image format -> (rows, cols, channels)\n",
    "K.set_image_data_format(\"channels_last\")\n",
    "# fix random seed for reproducibility\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5428.33333333\n",
      "{0: 0.07078770511377204, 65: 64.043209876543216, 35: 19.320297951582869, 100: 4.3665824915824913, 5: 0.29950059178430183, 70: 21.614583333333332, 40: 7.3738450604122248, 10: 0.63830441737418486, 75: 138.33333333333334, 45: 30.336257309941519, 15: 2.5133236434108528, 80: 22.456709956709958, 50: 10.90956887486856, 20: 2.087105210219272, 85: 111.55913978494624, 55: 58.61581920903955, 25: 8.3534621578099841, 90: 27.666666666666668, 60: 14.653954802259888, 30: 5.45478443743428, 95: 384.25925925925924}\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('/data/joint_scoring/labels_train_regression.h5', 'r') as hf:\n",
    "    labels_train = hf['labels_train_regression'][:]\n",
    "\n",
    "def round_x(x, base=5):\n",
    "    return int(base * round(float(x)/base))\n",
    "    \n",
    "labels_train_rounded = [ round_x(x) for x in labels_train ]\n",
    "\n",
    "classes = np.unique(labels_train_rounded)\n",
    "\n",
    "# define class weights because of imbalance\n",
    "weights = class_weight.compute_class_weight(class_weight='balanced', \n",
    "                                                 classes=classes, \n",
    "                                                 y=labels_train_rounded)\n",
    "\n",
    "print(max(weights)/min(weights))\n",
    "\n",
    "weights = dict(zip(classes, weights))\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.fit does not work with class_weights for a HDF5 Matrix\n",
    "# therefore, create sample weights\n",
    "\n",
    "sample_weights = [ weights[x] for x in labels_train_rounded ]\n",
    "\n",
    "sample_weights = np.array(sample_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data as HDF5 Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_train = HDF5Matrix('/data/joint_scoring/img_train_regression.h5', 'img_train_regression')\n",
    "img_test = HDF5Matrix('/data/joint_scoring/img_test_regression.h5', 'img_test_regression')\n",
    "\n",
    "labels_train = HDF5Matrix('/data/joint_scoring/labels_train_regression.h5', 'labels_train_regression')\n",
    "labels_test = HDF5Matrix('/data/joint_scoring/labels_test_regression.h5', 'labels_test_regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x / 255., input_shape=(150, 150, 1)))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=256, kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Dense(units=256, kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Dense(units=1, kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\",\n",
    "                  metrics=[\"mae\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_1 (Lambda)            (None, 150, 150, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 150, 150, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 150, 150, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 150, 150, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 150, 150, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 150, 150, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 150, 150, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 75, 75, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 75, 75, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 75, 75, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 75, 75, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 37, 37, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 37, 37, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 37, 37, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 37, 37, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 18, 18, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 18, 18, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 18, 18, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 18, 18, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 9, 9, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 9, 9, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 9, 9, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 1)                 4         \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 876,965\n",
      "Trainable params: 874,147\n",
      "Non-trainable params: 2,818\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = conv_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create log directory\n",
    "now = datetime.now\n",
    "new_folder = '{}'.format(now().strftime('%Y%m%d_%H%M%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171028_153155\n"
     ]
    }
   ],
   "source": [
    "print(new_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "desc = \"Regression model on original data\"\n",
    "\n",
    "with open(\"/data/joint_scoring/readme.txt\", \"a\") as myfile:\n",
    "    myfile.write(\"\\n\" + new_folder + \"    \" + desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tensorboard callback\n",
    "tb_callback = callbacks.TensorBoard(log_dir=\"/data/joint_scoring/tensorboard/\" + new_folder,\n",
    "                                    histogram_freq=0, write_graph=True,\n",
    "                                    write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72625 samples, validate on 19709 samples\n",
      "Epoch 1/25\n",
      "72625/72625 [==============================] - 188s - loss: 170.3552 - mean_absolute_error: 4.9649 - val_loss: 152.4259 - val_mean_absolute_error: 4.8305\n",
      "Epoch 2/25\n",
      "72625/72625 [==============================] - 181s - loss: 154.4028 - mean_absolute_error: 4.9731 - val_loss: 144.1160 - val_mean_absolute_error: 5.3793\n",
      "Epoch 3/25\n",
      "72625/72625 [==============================] - 179s - loss: 140.1580 - mean_absolute_error: 4.9688 - val_loss: 124.1918 - val_mean_absolute_error: 4.8972\n",
      "Epoch 4/25\n",
      "72625/72625 [==============================] - 178s - loss: 127.0507 - mean_absolute_error: 4.9562 - val_loss: 114.2044 - val_mean_absolute_error: 4.9947\n",
      "Epoch 5/25\n",
      "72625/72625 [==============================] - 177s - loss: 115.9126 - mean_absolute_error: 4.9396 - val_loss: 135.0915 - val_mean_absolute_error: 4.8110\n",
      "Epoch 6/25\n",
      "72625/72625 [==============================] - 177s - loss: 105.3560 - mean_absolute_error: 4.9111 - val_loss: 105.0349 - val_mean_absolute_error: 4.9171\n",
      "Epoch 7/25\n",
      "72625/72625 [==============================] - 177s - loss: 95.1361 - mean_absolute_error: 4.8433 - val_loss: 135.1340 - val_mean_absolute_error: 5.1015\n",
      "Epoch 8/25\n",
      "72625/72625 [==============================] - 177s - loss: 86.6608 - mean_absolute_error: 4.7721 - val_loss: 109.8148 - val_mean_absolute_error: 5.2376\n",
      "Epoch 9/25\n",
      "72625/72625 [==============================] - 177s - loss: 79.0471 - mean_absolute_error: 4.6772 - val_loss: 92.4064 - val_mean_absolute_error: 4.7521\n",
      "Epoch 10/25\n",
      "72625/72625 [==============================] - 177s - loss: 72.8424 - mean_absolute_error: 4.5719 - val_loss: 90.9502 - val_mean_absolute_error: 4.8038\n",
      "Epoch 11/25\n",
      "72625/72625 [==============================] - 177s - loss: 67.0379 - mean_absolute_error: 4.4478 - val_loss: 95.0303 - val_mean_absolute_error: 4.6998\n",
      "Epoch 12/25\n",
      "72625/72625 [==============================] - 176s - loss: 61.7634 - mean_absolute_error: 4.3292 - val_loss: 97.4751 - val_mean_absolute_error: 4.5243\n",
      "Epoch 13/25\n",
      "72625/72625 [==============================] - 176s - loss: 57.5387 - mean_absolute_error: 4.1927 - val_loss: 82.9693 - val_mean_absolute_error: 4.7009\n",
      "Epoch 14/25\n",
      "72625/72625 [==============================] - 176s - loss: 54.1712 - mean_absolute_error: 4.0793 - val_loss: 90.2299 - val_mean_absolute_error: 5.3593\n",
      "Epoch 15/25\n",
      "72625/72625 [==============================] - 176s - loss: 51.1887 - mean_absolute_error: 3.9534 - val_loss: 89.8448 - val_mean_absolute_error: 5.1652\n",
      "Epoch 16/25\n",
      "72625/72625 [==============================] - 175s - loss: 48.1010 - mean_absolute_error: 3.8524 - val_loss: 83.4669 - val_mean_absolute_error: 4.2963\n",
      "Epoch 17/25\n",
      "72625/72625 [==============================] - 176s - loss: 45.3722 - mean_absolute_error: 3.7329 - val_loss: 86.1668 - val_mean_absolute_error: 4.1657\n",
      "Epoch 18/25\n",
      "72625/72625 [==============================] - 176s - loss: 43.7195 - mean_absolute_error: 3.6545 - val_loss: 95.2070 - val_mean_absolute_error: 4.2530\n",
      "Epoch 19/25\n",
      "72625/72625 [==============================] - 176s - loss: 41.6735 - mean_absolute_error: 3.5629 - val_loss: 88.0583 - val_mean_absolute_error: 4.1288\n",
      "Epoch 20/25\n",
      "72625/72625 [==============================] - 176s - loss: 40.8031 - mean_absolute_error: 3.4962 - val_loss: 82.7755 - val_mean_absolute_error: 4.3198\n",
      "Epoch 21/25\n",
      "72625/72625 [==============================] - 176s - loss: 39.0854 - mean_absolute_error: 3.4151 - val_loss: 106.6294 - val_mean_absolute_error: 3.9651\n",
      "Epoch 22/25\n",
      "72625/72625 [==============================] - 177s - loss: 38.0978 - mean_absolute_error: 3.3460 - val_loss: 85.0608 - val_mean_absolute_error: 4.0600\n",
      "Epoch 23/25\n",
      "72625/72625 [==============================] - 178s - loss: 37.2347 - mean_absolute_error: 3.2796 - val_loss: 92.4341 - val_mean_absolute_error: 4.2058\n",
      "Epoch 24/25\n",
      "72625/72625 [==============================] - 178s - loss: 36.0494 - mean_absolute_error: 3.2208 - val_loss: 80.8133 - val_mean_absolute_error: 4.4920\n",
      "Epoch 25/25\n",
      "72625/72625 [==============================] - 178s - loss: 35.6738 - mean_absolute_error: 3.1816 - val_loss: 81.9393 - val_mean_absolute_error: 4.5451\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.contrib.keras.python.keras.callbacks.History at 0x7f47f0303550>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(x=img_train, y=labels_train, batch_size=100, epochs=25, verbose=1,\n",
    "          callbacks=[tb_callback], validation_data=(img_test, labels_test),\n",
    "          shuffle=\"batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[81.939261736321342, 4.5450772834372151]\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(img_test, labels_test, verbose=0)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"/data/joint_scoring/models/\" + new_folder + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19680/19709 [============================>.] - ETA: 0s0.0018627356334\n",
      "5.43873357349\n",
      "-0.0806372129\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, r2_score\n",
    "pred = model.predict_classes(img_test)\n",
    "\n",
    "print(explained_variance_score(labels_test, pred))\n",
    "print(mean_absolute_error(labels_test, pred))\n",
    "print(r2_score(labels_test, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGAqSpI6hIEnqGAqSpM7/AIItmRyRqM6wAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f47c42f2748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"True vs Predicted\")\n",
    "plt.ylabel('Predicted label')\n",
    "plt.xlabel('True label')\n",
    "plt.scatter(x=labels_test, y=pred)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbconvert import HTMLExporter\n",
    "import codecs\n",
    "import nbformat\n",
    "exporter = HTMLExporter()\n",
    "output_notebook = nbformat.read('deepxray_regression_weights.ipynb', as_version=4)\n",
    "output, resources = exporter.from_notebook_node(output_notebook)\n",
    "codecs.open(\"/data/joint_scoring/notebooks/\" + new_folder + \".html\", 'w', encoding='utf-8').write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
