{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Automatic scoring of x-ray images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# PIL to open & manipulate images\n",
    "from PIL import Image, ImageOps, ImageChops\n",
    "\n",
    "# for messages in loops\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# to save arrays\n",
    "import h5py\n",
    "\n",
    "# for folder-timestamp\n",
    "from datetime import datetime\n",
    "\n",
    "# for train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# for one-hot encoding\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "# for class weights\n",
    "from sklearn.utils import class_weight\n",
    "# for model evaluation\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# for efficient loops\n",
    "import itertools\n",
    "\n",
    "# keras\n",
    "from tensorflow.contrib.keras.python.keras import backend as K\n",
    "from tensorflow.contrib.keras.python.keras.utils.io_utils import HDF5Matrix\n",
    "from tensorflow.contrib.keras.python.keras.models import Sequential\n",
    "from tensorflow.contrib.keras.python.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Lambda, Activation\n",
    "from tensorflow.contrib.keras.python.keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.contrib.keras.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.contrib.keras.python.keras import callbacks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define image format & random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# image format -> (rows, cols, channels)\n",
    "K.set_image_data_format(\"channels_last\")\n",
    "# fix random seed for reproducibility\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5428.33333333\n",
      "{0: 0.07078770511377204, 65: 64.043209876543216, 35: 19.320297951582869, 100: 4.3665824915824913, 5: 0.29950059178430183, 70: 21.614583333333332, 40: 7.3738450604122248, 10: 0.63830441737418486, 75: 138.33333333333334, 45: 30.336257309941519, 15: 2.5133236434108528, 80: 22.456709956709958, 50: 10.90956887486856, 20: 2.087105210219272, 85: 111.55913978494624, 55: 58.61581920903955, 25: 8.3534621578099841, 90: 27.666666666666668, 60: 14.653954802259888, 30: 5.45478443743428, 95: 384.25925925925924}\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('/data/joint_scoring/labels_train_regression.h5', 'r') as hf:\n",
    "    labels_train = hf['labels_train_regression'][:]\n",
    "\n",
    "def round_x(x, base=5):\n",
    "    return int(base * round(float(x)/base))\n",
    "    \n",
    "labels_train_rounded = [ round_x(x) for x in labels_train ]\n",
    "\n",
    "classes = np.unique(labels_train_rounded)\n",
    "\n",
    "# define class weights because of imbalance\n",
    "weights = class_weight.compute_class_weight(class_weight='balanced', \n",
    "                                                 classes=classes, \n",
    "                                                 y=labels_train_rounded)\n",
    "\n",
    "print(max(weights)/min(weights))\n",
    "\n",
    "weights = dict(zip(classes, weights))\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.fit does not work with class_weights for a HDF5 Matrix\n",
    "# therefore, create sample weights\n",
    "\n",
    "sample_weights = [ weights[x] for x in labels_train_rounded ]\n",
    "\n",
    "sample_weights = np.array(sample_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data as HDF5 Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_train = HDF5Matrix('/data/joint_scoring/img_train_regression.h5', 'img_train_regression')\n",
    "img_test = HDF5Matrix('/data/joint_scoring/img_test_regression.h5', 'img_test_regression')\n",
    "\n",
    "labels_train = HDF5Matrix('/data/joint_scoring/labels_train_regression.h5', 'labels_train_regression')\n",
    "labels_test = HDF5Matrix('/data/joint_scoring/labels_test_regression.h5', 'labels_test_regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x / 255., input_shape=(150, 150, 1)))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=256, kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Dense(units=256, kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Dense(units=1, kernel_initializer=\"he_normal\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\",\n",
    "                  metrics=[\"mae\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_1 (Lambda)            (None, 150, 150, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 150, 150, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 150, 150, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 150, 150, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 150, 150, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 150, 150, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 150, 150, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 75, 75, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 75, 75, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 75, 75, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 75, 75, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 37, 37, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 37, 37, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 37, 37, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 37, 37, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 18, 18, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 18, 18, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 18, 18, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 18, 18, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 9, 9, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 9, 9, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 9, 9, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 1)                 4         \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 876,965\n",
      "Trainable params: 874,147\n",
      "Non-trainable params: 2,818\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = conv_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create log directory\n",
    "now = datetime.now\n",
    "new_folder = '{}'.format(now().strftime('%Y%m%d_%H%M%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20171101_085226\n"
     ]
    }
   ],
   "source": [
    "print(new_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "desc = \"Regression model with weights\"\n",
    "\n",
    "with open(\"/data/joint_scoring/readme.txt\", \"a\") as myfile:\n",
    "    myfile.write(\"\\n\" + new_folder + \"    \" + desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tensorboard callback\n",
    "tb_callback = callbacks.TensorBoard(log_dir=\"/data/joint_scoring/tensorboard/\" + new_folder,\n",
    "                                    histogram_freq=0, write_graph=True,\n",
    "                                    write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72625 samples, validate on 19709 samples\n",
      "Epoch 1/25\n",
      "72625/72625 [==============================] - 198s - loss: 3323.1869 - mean_absolute_error: 5.3870 - val_loss: 227.4337 - val_mean_absolute_error: 5.2558\n",
      "Epoch 2/25\n",
      "72625/72625 [==============================] - 185s - loss: 3231.1732 - mean_absolute_error: 5.4484 - val_loss: 220.6531 - val_mean_absolute_error: 5.2309\n",
      "Epoch 3/25\n",
      "72625/72625 [==============================] - 184s - loss: 3017.4465 - mean_absolute_error: 5.4062 - val_loss: 219.8864 - val_mean_absolute_error: 5.1520\n",
      "Epoch 4/25\n",
      "72625/72625 [==============================] - 185s - loss: 2833.1073 - mean_absolute_error: 5.4652 - val_loss: 196.1171 - val_mean_absolute_error: 5.2667\n",
      "Epoch 5/25\n",
      "72625/72625 [==============================] - 184s - loss: 2663.0349 - mean_absolute_error: 5.5527 - val_loss: 182.6318 - val_mean_absolute_error: 5.2484\n",
      "Epoch 6/25\n",
      "72625/72625 [==============================] - 185s - loss: 2468.2438 - mean_absolute_error: 5.6699 - val_loss: 171.4331 - val_mean_absolute_error: 5.4527\n",
      "Epoch 7/25\n",
      "72625/72625 [==============================] - 184s - loss: 2370.7783 - mean_absolute_error: 5.8112 - val_loss: 178.8758 - val_mean_absolute_error: 5.5445\n",
      "Epoch 8/25\n",
      "72625/72625 [==============================] - 185s - loss: 2145.5235 - mean_absolute_error: 5.8781 - val_loss: 183.7112 - val_mean_absolute_error: 5.9480\n",
      "Epoch 9/25\n",
      "72625/72625 [==============================] - 184s - loss: 2022.8699 - mean_absolute_error: 6.0283 - val_loss: 159.5152 - val_mean_absolute_error: 5.7836\n",
      "Epoch 10/25\n",
      "72625/72625 [==============================] - 185s - loss: 1826.5305 - mean_absolute_error: 6.1453 - val_loss: 152.5231 - val_mean_absolute_error: 5.9727\n",
      "Epoch 11/25\n",
      "72625/72625 [==============================] - 184s - loss: 1649.2708 - mean_absolute_error: 6.2239 - val_loss: 151.8659 - val_mean_absolute_error: 6.2189\n",
      "Epoch 12/25\n",
      "72625/72625 [==============================] - 184s - loss: 1570.2274 - mean_absolute_error: 6.4098 - val_loss: 175.3225 - val_mean_absolute_error: 6.3121\n",
      "Epoch 13/25\n",
      "72625/72625 [==============================] - 184s - loss: 1379.6793 - mean_absolute_error: 6.5051 - val_loss: 150.1397 - val_mean_absolute_error: 6.6326\n",
      "Epoch 14/25\n",
      "72625/72625 [==============================] - 185s - loss: 1221.3859 - mean_absolute_error: 6.6260 - val_loss: 149.2212 - val_mean_absolute_error: 7.2799\n",
      "Epoch 15/25\n",
      "72625/72625 [==============================] - 184s - loss: 1121.5740 - mean_absolute_error: 6.8346 - val_loss: 141.0974 - val_mean_absolute_error: 6.8183\n",
      "Epoch 16/25\n",
      "72625/72625 [==============================] - 185s - loss: 965.8242 - mean_absolute_error: 7.0267 - val_loss: 166.6229 - val_mean_absolute_error: 8.0389\n",
      "Epoch 17/25\n",
      "72625/72625 [==============================] - 184s - loss: 883.1485 - mean_absolute_error: 7.2381 - val_loss: 158.6402 - val_mean_absolute_error: 7.6264\n",
      "Epoch 18/25\n",
      "72625/72625 [==============================] - 185s - loss: 767.9291 - mean_absolute_error: 7.4359 - val_loss: 142.1920 - val_mean_absolute_error: 7.4728\n",
      "Epoch 19/25\n",
      "72625/72625 [==============================] - 184s - loss: 696.5690 - mean_absolute_error: 7.6518 - val_loss: 146.4226 - val_mean_absolute_error: 7.7115\n",
      "Epoch 20/25\n",
      "72625/72625 [==============================] - 185s - loss: 624.3015 - mean_absolute_error: 7.8796 - val_loss: 141.8011 - val_mean_absolute_error: 8.1766\n",
      "Epoch 21/25\n",
      "72625/72625 [==============================] - 184s - loss: 565.2738 - mean_absolute_error: 8.0809 - val_loss: 144.7988 - val_mean_absolute_error: 8.4475\n",
      "Epoch 22/25\n",
      "72625/72625 [==============================] - 185s - loss: 525.6305 - mean_absolute_error: 8.3445 - val_loss: 148.2406 - val_mean_absolute_error: 8.6722\n",
      "Epoch 23/25\n",
      "72625/72625 [==============================] - 184s - loss: 450.5791 - mean_absolute_error: 8.5207 - val_loss: 149.9953 - val_mean_absolute_error: 8.8468\n",
      "Epoch 24/25\n",
      "72625/72625 [==============================] - 185s - loss: 418.5245 - mean_absolute_error: 8.7333 - val_loss: 149.7317 - val_mean_absolute_error: 8.9051\n",
      "Epoch 25/25\n",
      "72625/72625 [==============================] - 184s - loss: 423.1407 - mean_absolute_error: 9.0769 - val_loss: 148.1129 - val_mean_absolute_error: 9.0929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.contrib.keras.python.keras.callbacks.History at 0x7f48dd1de710>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(x=img_train, y=labels_train, batch_size=100, epochs=25, verbose=1,\n",
    "          callbacks=[tb_callback], validation_data=(img_test, labels_test),\n",
    "          shuffle=\"batch\", sample_weight=sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[148.1128527164048, 9.0929152342432307]\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(img_test, labels_test, verbose=0)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"/data/joint_scoring/models/\" + new_folder + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19648/19709 [============================>.] - ETA: 0s0.0\n",
      "5.47912121366\n",
      "-0.0807495593956\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, r2_score\n",
    "pred = model.predict_classes(img_test)\n",
    "\n",
    "print(explained_variance_score(labels_test, pred))\n",
    "print(mean_absolute_error(labels_test, pred))\n",
    "print(r2_score(labels_test, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHjtJREFUeJzt3Xu8VmWd9/HPNw6JqaGAZoCKwktjlNC2ijmmWRaK46ma\nNE1zTKrHJqdJR7RM85FhTDs5NRpTiDR5GnUKy8RDmk4GuRVEyygiDbYk2xDFwyOiv+ePdW1dbvd9\nYK+99s19832/Xvdr3+tap2u5ZH/3uq61rqWIwMzMrLfe1OgKmJlZc3OQmJlZIQ4SMzMrxEFiZmaF\nOEjMzKwQB4mZmRXiIDFrMZIulDQ7fd9Z0rP9tN8Vkg7qj33ZxsVBYk1F0rO5zyuSXshNH9/o+tVD\n0vtT3Z+VtFbS7ySdVMa+ImJZRGxRZ50eLaMO1voGNroCZhsi/0sx/eL7ZETcXml5SQMjYn1/1G0D\n/TkidpIk4BjgWknzI2JJfqGNuP5mr/IVibWU1KxzraSrJa0FTpD0X5LOzy3zur++JY2S9D+SOiX9\nSdJpFba9v6QOSW/KlX1E0gPp+yRJD0h6RtITki6uVd/I3ACsBd4haaykkHSypD8Dt+b2PV/SGkmL\nJL0nV4edJd2Trm7mAcNy88ZKitz0MEmzJa2U9JSkGyS9FbgJ2CF3dbetpDdJOkfSHyU9KekaSVvn\ntvUJSY+ledNqHau1LgeJtaKjgauAtwLXVlswhcJPgPuAkcAhwJmS3tfD4vcCLwEH5so+lvYF8O/A\nxRGxFTAWuL5WRdMv6w8DWwAP5Wa9B9gNmCJpNDAXOA/YBpgG3CipKzCuBeYDw4EZwMer7PIqYDAw\nHtgW+FZEPA38HdlV0hbpswr4PDAl1WUU8Cxwaar3HsC30/GPBN4OvK3W8VprcpBYK/rfiLgpIl6J\niBdqLLsfsFVE/GtErIuIpcD3gWO7LxjZwHTXAMcBSBoKfDCVQRYy4yQNi4i1EbGgyn53kLQGeBL4\nInB8RPwxN/+8iHg+1f9EYG5EzEvHdAvwIDBZ0s7AO9PyL0bEXcDNPe0wBdL7gM9ExFMR8VJE3F2l\njp8GzomIjoj4f8BXgI+k8P0I8KOI+GVEvAicA6jKtqyFuY/EWtHyDVh2R177pd5lAHBXheWvAu5M\nzV8fAhZExIo072SyX7ZLJC0Dzo+IHn+pk/pIqtQrfww7AsdJOjpXNgi4hexK4K8R8Xxu3mPAiB62\nORp4Ml2B1GMH4CZJr3Qr3zbt99U6RsSzklbXuV1rMQ4Sa0Xdh7R+Dtg8N51vglkO/CEi3lHXhiMW\nS/oL2ZVIvlmL1FF+bO4v9hskbZ3+mt+wA3j9sNzLgSsi4jPdl5O0CzBM0pDc1dcOQE9XYsuB4ZK2\niohnuu+yh+VXAB/r6cpK0kpgTG56C7JmN9sEuWnLNgWLyPoatpa0PfC53LxfAeskfUHSZpIGSNpD\n0ruqbO8qsv6D/cj1g0j6uKThEfEK8DTZL+fuf833xg+AoyUdkuq3maT3Snp7ag5bDJwvaXDqhJ/S\n00YiYjlwO/AdSUMlDcp12j9BFjJb5la5HPhXSTuk49tW0hFp3n8DR0raT9KbgQvpOYxsE+AgsU3B\nbOARsiafW3itT4N0a+1hwD7Ao2R9Ft8FtqqyvauAg4HbIuKpXPlhwCPpbrFLgI9GxLqilY+IR8lu\nIDgX6AT+DHyB1/79HgvsD6wm62/5QZXNnZB+/p4sPP4x7eNh4Abg0XRn2LbA18n+e92RjuleYO+0\n/GLgdOA6oAP4S/rYJkh+sZWZmRXhKxIzMyvEQWJmZoWUFiSSZklaJenhCvMl6VJJSyUtlrRXbt4t\nqZ32J93WmZ2ePF6UPhPLqr+ZmdWnzCuS2cDkKvMPBcalz1Tgsty8i6n8dO6ZETExfRb1RUXNzKz3\nSnuOJCLulrRTlUWOBOak++Xnp9sRt4+IlRFxh/pwOOrhw4fHTjtVq4qZmXV3//33PxkRPT3c+jqN\nfCBxJK9/endFKltZY73pkr4M3AFMS8MzVLXTTjvR3t7e64qamW2KJD1Wz3LN1tl+NtlAdnuTPUV7\nVqUFJU2V1C6pvbOzs7/qZ2a2yWlkkHSQjf3TZVQqqyg1e0W6CrmC7CGySsvOjIi2iGgbMaLmlZmZ\nmfVSI4NkLnBiuntrEvB0RFRt1krDWyBJwFFAj3eEmZlZ/ymtj0TS1cBBZOP3rCB7l8IggIi4nGyo\n68OApcDzZCOndq17D1kT1hZp3VMiYh7wQ0kjyIarXkQ2zLWZmTVQmXdtHVdjfgA9vokuIg6oUH5w\nH1TNzMz6ULN1tpuZ2UbGQWJmZoU4SMzMrBAHiZmZFeIgMTOzQhwkZmZWiIPEzMwKcZCYmVkhDhIz\nMyvEQWJmZoU4SMzMrBAHiZmZFeIgMTOzQhwkZmZWiIPEzMwKcZCYmVkhDhIzMyvEQWJmZoU4SMzM\nrBAHiZmZFeIgMTOzQhwkZmZWiIPEzMwKcZCYmVkhDhIzMyvEQWJmZoU4SMzMrJDSgkTSLEmrJD1c\nYb4kXSppqaTFkvbKzbtF0hpJP+m2zhhJC9I610oaXFb9zcysPmVekcwGJleZfygwLn2mApfl5l0M\nfLyHdS4CvhERY4GngFP6pKZmZtZrpQVJRNwNrK6yyJHAnMjMB4ZK2j6tewewNr+wJAEHA9enoiuB\no/q84mZmtkEa2UcyEliem16RyioZBqyJiPX1LC9pqqR2Se2dnZ2FK2tmZj1r2c72iJgZEW0R0TZi\nxIhGV8fMrGU1Mkg6gNG56VGprJK/kjV/DaxzeTMz6weNDJK5wInp7q1JwNMRsbLSwhERwJ3Ah1PR\nScCPy6+mmZlVM7D2Ir0j6WrgIGC4pBXAecAggIi4HLgZOAxYCjwPnJxb9x5gN2CLtO4pETEPOAu4\nRtKFwELg+2XV38zM6lNakETEcTXmB3BahXkHVChfBuxTvHZmZtZXWraz3czM+oeDxMzMCnGQmJlZ\nIQ4SMzMrxEFiZmaFOEjMzKwQB4mZmRXiIDEzs0IcJGZmVoiDxMzMCnGQmJlZIQ4SMzMrxEFiZmaF\nOEjMzKwQB4mZmRXiIDEzs0IcJGZmVoiDxMzMCnGQmJlZIQ4SMzMrxEFiZmaFOEjMzKwQB4mZmRXi\nIDEzs0IcJGZmVoiDxMzMCnGQmJlZIaUFiaRZklZJerjCfEm6VNJSSYsl7ZWbd5KkP6TPSbnyuyQt\nkbQofbYtq/5mZlafMq9IZgOTq8w/FBiXPlOBywAkbQOcB+wL7AOcJ2nr3HrHR8TE9FlVRsXNzKx+\npQVJRNwNrK6yyJHAnMjMB4ZK2h74IHBbRKyOiKeA26geSGZm1kCN7CMZCSzPTa9IZZXKu1yRmrXO\nlaRKG5c0VVK7pPbOzs6+rLeZmeUMrDRD0kNA9DQLiIiYUFqtKjs+IjokbQncAHwcmNPTghExE5gJ\n0NbW1tNxmJlZH6gYJMDhJe+7Axidmx6VyjqAg7qV3wUQER3p51pJV5H1ofQYJGZm1j8qNm1FxGNd\nn1Q0Ln1fRfW+j3rNBU5Md29NAp6OiJXAPOADkrZOnewfAOZJGihpOICkQWRB1+MdYWZm1n+qXZEA\nIOlUsruqtgF2IbtCuBx4X431ria7shguaQXZnViDACLicuBm4DBgKfA8cHKat1rS/wXuS5u6IJW9\nhSxQBgEDgNuB/9yQgzUzs76niOrdB5IWkTUhLYiIPVPZQxGxRz/Ur0+0tbVFe3t7o6thZtZUJN0f\nEW21lqvnrq0XI2JdbsMD6bkT3szMNkH1BMkvJJ0DDJF0CPDfwE3lVsvMzJpFPUEyDegEHgI+Rda3\n8aUyK2VmZs2jZmd7RLwi6UpgAVmT1pKo1bFiZmabjHru2ppCdpfWH8keRhwj6VMR8bOyK2dmZhu/\nmkECfA14b0QsBZC0C/BTwEFiZmZ19ZGs7QqRZBmwtqT6mJlZk6k21tYx6Wu7pJuB68j6SD7Caw8L\nmpnZJq5a09bf5b4/ARyYvncCQ0qrkZmZNZWKQRIRJ/dnRczMrDnVc9fWZsApwN8Am3WVR8Q/lFgv\nMzNrEvV0tv8AeBvZmwt/QTZoozvbzcwMqC9IxkbEucBzEXElMIXsfepmZmZ1BclL6ecaSbsDbwW2\nLa9KZmbWTOp5IHFmesHUuWQvo9oC+HKptTIzs6ZRz1hb30tffwHsXG51zMys2VR7IPGfq60YEV/v\n++qYmVmzqXZFsmW/1cLMzJpWtQcSv9KfFTEzs+ZUz11bZmZmFTlIzMysEAeJmZkV4ru2zMyskHru\n2toV2JvsYUTIhpf/dZmVMjOz5lHzri1JdwN7RcTaNH0+2at2zczM6uoj2Q5Yl5tel8rMzMzqGmtr\nDvBrSf+Tpo8CriyvSmZm1kzqGWtruqSfAQekopMjYmE9G5c0CzgcWBURu/cwX8C3gMOA54FPRMQD\nad5JwJfSohemIeyR9C5gNtnrfm8GTo+IqKc+G2KnaW9svXv036aUvm4j992M6zZy3xv7uj9a2MHF\n85bw+JoXePvQIZz5wV05as+RG329ezJm2k/J/yMX8Kd++n9k7Nk/ZX1u5wMFS2eUf8z7Tr+NJ9a+\n1hi03ZaDWfDFQ0rfb2/Ue/vv5sAzEfEtYIWkMXWuNxuYXGX+ocC49JkKXAYgaRvgPLL3nuwDnJdG\nICYtc2puvWrb75WeTkK18r5at5H7bsZ1G7nvjX3dHy3s4OwbH6JjzQsE0LHmBc6+8aGNvt496R4i\nAJHK61Fk391DBGB9ZOVl7rd7iAA8sXYd+06/rdT99lbNIJF0HnAWcHYqGgT8Vz0bj4i7gdVVFjkS\nmBOZ+cBQSduTvY3xtohYHRFPAbcBk9O8rSJifroKmUPW1GZmORfPW8ILL738urLu082iUnNDnzdD\n9KB7iNQq7yvdQ6RWeaPVc0VyNHAE8BxARDxO3w3oOBJYnptekcqqla/oofwNJE2V1C6pvbOzs4+q\na9YcHl/zQqOrYJuQeoJkXfrrPwAkvaXcKvWNiJgZEW0R0TZixIhGV8esX7196JBGV8E2IfUEyXWS\nvkvW7HQqcDvwvRrr1KsDGJ2bHpXKqpWP6qHczHLO/OCuDBk04HVl3aebhTawvC8NrLCTSuV9Zbst\nB29QeaPVDJKIuAS4HriB7Cn3L0fEpX20/7nAicpMAp6OiJXAPOADkrZOnewfAOalec9ImpTu+DoR\n+HEf1eVVle5uqOeuhyLrNnLfzbhuI/e9sa971J4jmXHMHowcOgQBI4cOYcYxe2z09e7Jn/5tyhtC\nY0Pu2iqy76UzprwhNOq9a6vIfhd88ZA3hEa9d20V/TfVG6p156ykiyLirFplFda9GjgIGA48QXYn\n1iCAiLg8hcG3ye68ep7s1uL2tO4/AOekTU2PiCtSeRuv3f77M+Afa93+29bWFu3t7bWqa2ZmOZLu\nj4i2msvVESQPRMRe3coWR8SEgnXsNw4SM7MNV2+QVBv99zPA/wF2kbQ4N2tL4N7iVTQzs1ZQ7cn2\nq8iajmYA03LlayOi2rMhZma2CanY2R4RT0fEo2RDmKyOiMci4jFgvaR9+6uCZma2cavn9t/LgGdz\n08+mMjMzs7qCRPm7oiLiFeobNdjMzDYB9QTJMkmfkzQofU4HlpVdMTMzaw71BMmngXeTPUG+gmxE\n3qllVsrMzJpHPe8jWQUc2w91MTOzJlTtOZJ/iYivSvp3ehixOSI+V2rNzMysKVS7Inkk/fQj4WZm\nVlHFIImIm9JPv5/dzMwqqta0dRNVXkIWEUeUUiMzM2sq1Zq2Lkk/jwHexmuv1z2ObCRfMzOzqk1b\nvwCQ9LVuoz/eJMn9JmZmBtT3HMlbJO3cNSFpDNAUr9s1M7Py1TPUyeeBuyQtI3sx2Y7Ap0qtlZmZ\nNY16Hki8RdI4YLdU9LuIeLHcapmZWbOo2bQlaXPgTOCzEfEgsIOkw0uvmZmZNYV6+kiuANYB+6Xp\nDuDC0mpkZmZNpZ4g2SUivgq8BBARz5P1lZiZmdUVJOskDSE9nChpF8B9JGZmBtR319Z5wC3AaEk/\nBPYHPlFmpczMrHlUDRJJAn5H9nT7JLImrdMj4sl+qJuZmTWBqkESESHp5ojYA/hpP9XJzMyaSD19\nJA9I2rv0mpiZWVOqp49kX+AESY8Cz5E1b0VETCizYmZm1hzqCZIPll4LMzNrWhWbtiRtJumfyJ5q\nnwx0RMRjXZ96Ni5psqQlkpZKmtbD/B0l3SFpsaS7JI3KzbtI0sPp89Fc+WxJf5K0KH0mbtARm5lZ\nn6rWR3Il0AY8BBwKfG1DNixpAPCdtO544DhJ47stdgkwJzWTXQDMSOtOAfYCJpI1rZ0haavcemdG\nxMT0WbQh9TIzs75VLUjGR8QJEfFd4MPAARu47X2ApRGxLCLWAdcAR3bfB/Dz9P3O3PzxwN0RsT4i\nngMWk10VmZnZRqZakLzU9SUi1vdi2yOB5bnpFaks70GyZ1QAjga2lDQslU+WtLmk4cB7gdG59aan\n5rBvSHpzTzuXNFVSu6T2zs7OXlTfzMzqUS1I3inpmfRZC0zo+i7pmT7a/xnAgZIWAgeSDQj5ckTc\nCtwM3AtcDfwKeDmtczbZkPZ7A9sAZ/W04YiYGRFtEdE2YsSIPqqumZl1V+1VuwMKbruD119FjEpl\n+X08TroikbQF8KGIWJPmTQemp3lXAb9P5SvT6i9KuoIsjMzMrEHqeSCxt+4DxkkaI2kwcCwwN7+A\npOGSuupwNjArlQ9ITVxImgBMAG5N09unnwKOAh4u8RjMzKyGep4j6ZWIWC/ps8A8YAAwKyJ+I+kC\noD0i5gIHATMkBXA3cFpafRBwT5YVPAOckOun+aGkEWQPRi4CPl3WMZiZWW2KiEbXoXRtbW3R3t7e\n6GqYmTUVSfdHRFut5cps2jIzs02Ag8TMzApxkJiZWSEOEjMzK8RBYmZmhThIzMysEAeJmZkV4iAx\nM7NCHCRmZlaIg8TMzApxkJiZWSEOEjMzK8RBYmZmhThIzMysEAeJmZkV4iAxM7NCHCRmZlaIg8TM\nzApxkJiZWSEOEjMzK8RBYmZmhThIzMysEAeJmZkV4iAxM7NCHCRmZlaIg8TMzApxkJiZWSGlBomk\nyZKWSFoqaVoP83eUdIekxZLukjQqN+8iSQ+nz0dz5WMkLUjbvFbS4DKPwczMqistSCQNAL4DHAqM\nB46TNL7bYpcAcyJiAnABMCOtOwXYC5gI7AucIWmrtM5FwDciYizwFHBKWcdgZma1lXlFsg+wNCKW\nRcQ64BrgyG7LjAd+nr7fmZs/Hrg7ItZHxHPAYmCyJAEHA9en5a4EjirxGMzMrIYyg2QksDw3vSKV\n5T0IHJO+Hw1sKWlYKp8saXNJw4H3AqOBYcCaiFhfZZsASJoqqV1Se2dnZ58ckJmZvVGjO9vPAA6U\ntBA4EOgAXo6IW4GbgXuBq4FfAS9vyIYjYmZEtEVE24gRI/q42mZm1qXMIOkgu4roMiqVvSoiHo+I\nYyJiT+CLqWxN+jk9IiZGxCGAgN8DfwWGShpYaZtmZta/ygyS+4Bx6S6rwcCxwNz8ApKGS+qqw9nA\nrFQ+IDVxIWkCMAG4NSKCrC/lw2mdk4Afl3gMZmZWQ2lBkvoxPgvMAx4BrouI30i6QNIRabGDgCWS\nfg9sB0xP5YOAeyT9FpgJnJDrFzkL+GdJS8n6TL5f1jGYmVltyv7Ib21tbW3R3t7e6GqYmTUVSfdH\nRFut5Rrd2W5mZk3OQWJmZoU4SMzMrBAHiZmZFeIgMTOzQhwkZmZWiIPEzMwKcZCYmVkhDhIzMyvE\nQWJmZoU4SMzMrBAHiZmZFeIgMTOzQhwkZmZWiIPEzMwKcZCYmVkhDhIzMyvEQWJmZoU4SMzMrBAH\niZmZFeIgMTOzQhwkZmZWiIPEzMwKcZCYmVkhDhIzMyvEQWJmZoWUGiSSJktaImmppGk9zN9R0h2S\nFku6S9Ko3LyvSvqNpEckXSpJqfyutM1F6bNtmcdgZmbVlRYkkgYA3wEOBcYDx0ka322xS4A5ETEB\nuACYkdZ9N7A/MAHYHdgbODC33vERMTF9VpV1DGZmVluZVyT7AEsjYllErAOuAY7stsx44Ofp+525\n+QFsBgwG3gwMAp4osa5mZtZLZQbJSGB5bnpFKst7EDgmfT8a2FLSsIj4FVmwrEyfeRHxSG69K1Kz\n1rldTV5mZtYYje5sPwM4UNJCsqarDuBlSWOBdwCjyMLnYEkHpHWOj4g9gAPS5+M9bVjSVEntkto7\nOzvLPg4zs03WwBK33QGMzk2PSmWviojHSVckkrYAPhQRaySdCsyPiGfTvJ8B+wH3RERHWnetpKvI\nmtDmdN95RMwEZqb1OyU91svjGA482ct1m5WPedPgY259RY93x3oWKjNI7gPGSRpDFiDHAh/LLyBp\nOLA6Il4BzgZmpVl/Bk6VNAMQ2dXKNyUNBIZGxJOSBgGHA7fXqkhEjOjtQUhqj4i23q7fjHzMmwYf\nc+vrr+MtrWkrItYDnwXmAY8A10XEbyRdIOmItNhBwBJJvwe2A6an8uuBPwIPkfWjPBgRN5F1vM+T\ntBhYRBZQ/1nWMZiZWW1lXpEQETcDN3cr+3Lu+/VkodF9vZeBT/VQ/hzwrr6vqZmZ9VajO9ubwcxG\nV6ABfMybBh9z6+uX41VE9Md+zMysRfmKxMzMCnGQmJlZIQ6SKmoNOtnsJI2WdKek36YBMk9P5dtI\nuk3SH9LPrRtd174maYCkhZJ+kqbHSFqQzvW1kgY3uo59SdJQSddL+l0aCHW/Vj/Pkj6f/r9+WNLV\nkjZrtfMsaZakVZIezpX1eF6VuTQd+2JJe/VVPRwkFdQ56GSzWw98ISLGA5OA09IxTgPuiIhxwB1p\nutWcTnZbepeLgG9ExFjgKeCUhtSqPN8CbomI3YB3kh17y55nSSOBzwFtEbE7MIDsWbZWO8+zgcnd\nyiqd10OBcekzFbisryrhIKmsnkEnm1pErIyIB9L3tWS/XEaSHeeVabErgaMaU8NypNcVTAG+l6YF\nHMxrt6K31DFLeivwHuD7ABGxLiLW0OLnmezxhiHpQebNycbta6nzHBF3A6u7FVc6r0eSjbYeETEf\nGCpp+76oh4OksnoGnWwZknYC9gQWANtFxMo06y9kD4u2km8C/wK8kqaHAWvSQ7TQeud6DNBJNtjp\nQknfk/QWWvg8p6GULiEbJWMl8DRwP619nrtUOq+l/U5zkFjXOGc3AP8UEc/k50V2f3jL3CMu6XBg\nVUTc3+i69KOBwF7AZRGxJ/Ac3ZqxWvA8b032F/gY4O3AW3hjE1DL66/z6iCprOagk60gjVl2A/DD\niLgxFT/RdcmbfrbSy8P2B46Q9ChZc+XBZP0HQ1MTCLTeuV4BrIiIBWn6erJgaeXz/H7gTxHRGREv\nATeSnftWPs9dKp3X0n6nOUgqe3XQyXRnx7HA3AbXqU+lvoHvA49ExNdzs+YCJ6XvJwE/7u+6lSUi\nzo6IURGxE9k5/XlEHE/2/psPp8Va7Zj/AiyXtGsqeh/wW1r4PJM1aU2StHn6/7zrmFv2POdUOq9z\ngRPT3VuTgKdzTWCF+Mn2KiQdRtaePgCYFRHTa6zSVCT9LXAP2eCYXf0F55D1k1wH7AA8Bvx9RHTv\n0Gt6kg4CzoiIwyXtTHaFsg2wEDghIl5sZP36kqSJZDcXDAaWASeT/SHZsudZ0leAj5LdnbgQ+CRZ\nn0DLnGdJV5MNfjuc7C2y5wE/oofzmgL122RNfM8DJ0dEe5/Uw0FiZmZFuGnLzMwKcZCYmVkhDhIz\nMyvEQWJmZoU4SMzMrBAHiVkFkoZJWpQ+f5HUkZvus1FjJb1f0o9qLPNJSd/cwO2ukDS0WO3Maiv1\nne1mzSwi/gpMBJB0PvBsRFySXybdm6+IeOWNWzDbNPiKxGwDSRqb3uHyQ+A3wGhJa3Lzj5XUNbLw\ndpJulNQu6dfpieJq254k6VdpcMVfShqXm72jpF+k90x8KbfOSWnbiyT9hyT/u7Z+5SsSs97ZDTgx\nItpzYzf15FLgqxExP42w/BNg9yrLPwIcEBHrJU0GLiR7OhuyVxvsDqwD7lP2Uq71wNHAu9M6M8mG\nfrmq94dmtmEcJGa988c6h5d4P7Br1gIGwNaShkTECxWWHwrMkbRLD/PmRcRTAKlP5W/J/g3vDbSn\nfQzh9UOFm5XOQWLWO8/lvr8CKDe9We67gH3Sy9HqMZ0sMP5D0ljglty87uMZRdr+rIg4t87tm/U5\nt6WaFZQ62p+SNC71Txydm307cFrXRBo8sZq38trQ3p/oNu8Dyt69vjnZuzZ+mbb/95KGp+0Pk7RD\nrw/GrBccJGZ94yxgHnAv2fs/upwG7C9psaTfAqfW2M5FwMWSHuD1VzmQvdrgx8CDwNURsSgiHgK+\nAtwuaTFwKy30pkNrDh7918zMCvEViZmZFeIgMTOzQhwkZmZWiIPEzMwKcZCYmVkhDhIzMyvEQWJm\nZoX8fxTVGSZfBSwaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f48a0162e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"True vs Predicted\")\n",
    "plt.ylabel('Predicted label')\n",
    "plt.xlabel('True label')\n",
    "plt.scatter(x=labels_test, y=pred)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nbconvert import HTMLExporter\n",
    "import codecs\n",
    "import nbformat\n",
    "exporter = HTMLExporter()\n",
    "output_notebook = nbformat.read('deepxray_regression_weights.ipynb', as_version=4)\n",
    "output, resources = exporter.from_notebook_node(output_notebook)\n",
    "codecs.open(\"/data/joint_scoring/notebooks/\" + new_folder + \".html\", 'w', encoding='utf-8').write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
