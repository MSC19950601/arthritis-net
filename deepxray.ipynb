{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Automatic scoring of x-ray images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# PIL to open & manipulate images\n",
    "from PIL import Image, ImageOps, ImageChops\n",
    "\n",
    "# for messages in loops\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# for train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for one-hot encoding\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# keras\n",
    "from tensorflow.contrib.keras.python.keras import backend as K\n",
    "from tensorflow.contrib.keras.python.keras.models import Sequential\n",
    "from tensorflow.contrib.keras.python.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.contrib.keras.python.keras import callbacks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define image format & random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# image format -> (rows, cols, channels)\n",
    "K.set_image_data_format(\"channels_last\")\n",
    "# fix random seed for reproducibility\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filepath_or_buffer=\"/data/deepxray/data/rau_data/merged.csv\")\n",
    "#df = pd.read_csv(filepath_or_buffer=\"/Volumes/deepxray/data/rau_data/merged.csv\")\n",
    "df = df.loc[df['body_part'].isin([\"HAND_LEFT\", \"HAND_BOTH\"])]\n",
    "names = df[\"sop_iuid\"].as_matrix()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load images and labels into numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root = \"/data\"\n",
    "#root = \"/Volumes\"\n",
    "dirname = \"deepxray/joint_detection/output\"\n",
    "\n",
    "# function to remove black bars from image (preparation for histogram equalization)\n",
    "def trim(im):\n",
    "    # create a black image with the same size as original\n",
    "    bg = Image.new(mode=im.mode, size=im.size, color=0)\n",
    "    # get difference between image and background\n",
    "    diff = ImageChops.difference(image1=im, image2=bg)\n",
    "    # ensures, that the whole border gets removed (fuzzy border due to compression of jpg)\n",
    "    diff = ImageChops.add(image1=diff, image2=diff, scale=2.0, offset=-100)\n",
    "    bbox = diff.getbbox()\n",
    "    if bbox:\n",
    "        return im.crop(bbox)\n",
    "\n",
    "# function to load and preprocess the image\n",
    "def preprocess_img(xray_name, joint_name):\n",
    "    # folder name\n",
    "    folder_name = \"predictions_extract_\" + joint_name\n",
    "    # file name\n",
    "    file_name = xray_name + \"_\" + joint_name + \".jpg\"\n",
    "    \n",
    "    # read image\n",
    "    image = Image.open(fp=os.path.join(root, dirname, folder_name, file_name))\n",
    "    image_w, image_h = image.size\n",
    "    \n",
    "    # histogram normalization (remaps the image -> lightest pixel = 255, darkest pixel = 0)\n",
    "    img = trim(image)\n",
    "    img_w, img_h = img.size\n",
    "    img = ImageOps.autocontrast(image=img)\n",
    "    offset = (int((image_w - img_w) / 2), int((image_h - img_h) / 2))\n",
    "    image.paste(img, offset)\n",
    "    \n",
    "    # turn into np array\n",
    "    data = np.asarray(a=image, dtype=\"uint8\")\n",
    "    return(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_score(joint_number, index):\n",
    "    score = df[joint_number].as_matrix()[index]\n",
    "    return(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_numbers = [\"hand_left_1\", \"hand_left_2\", \"hand_left_3\", \"hand_left_4\", \"hand_left_5\", \n",
    "                 \"hand_left_6\", \"hand_left_7\", \"hand_left_8\", \"hand_left_9\", \"hand_left_10\"]\n",
    "joint_names = [\"pip5\", \"mcp5\", \"pip4\", \"mcp4\", \"pip3\", \"mcp3\", \"mcp2\", \"pip2\", \"mcp1\", \"pip1\"]\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print(joint_numbers[i] + \" -> \" + joint_names[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "n_img = names.shape[0]\n",
    "\n",
    "for i, xray_name in enumerate(names):\n",
    "    if (i % 100) == 0:\n",
    "        clear_output()\n",
    "        print(\"Importing images, {0:.2f} % finished\".format(i/n_img*100))\n",
    "        \n",
    "    for joint in range(10):\n",
    "        try:\n",
    "            img = preprocess_img(xray_name, joint_names[joint])\n",
    "        except Exception: \n",
    "            pass\n",
    "        else:\n",
    "            lbl = get_score(joint_numbers[joint], i)\n",
    "            if np.isnan(lbl):\n",
    "                continue\n",
    "            else:\n",
    "                images.append(img)\n",
    "                labels.append(lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "#print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):    \n",
    "    plt.imshow(images[i].squeeze(), cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images = np.array(images)\n",
    "np.save(file=\"/data/joint_scoring/img_array.npy\", arr=images)\n",
    "#np.save(file=\"/Users/janickrohrbach/Desktop/joint_scoring/img_array.npy\", arr=images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = np.load(file=\"/data/body_part_classification/img_array.npy\")\n",
    "#images = np.load(file=\"/Users/janickrohrbach/Desktop/joint_scoring/img_array.npy\")\n",
    "images = images.reshape(images.shape[0], images.shape[1], images.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create four classes\n",
    "labels[labels <= 25] = 0\n",
    "labels[(labels > 25) & (labels <= 50)] = 1\n",
    "labels[(labels > 50) & (labels <= 75)] = 2\n",
    "labels[labels > 75] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_train, img_test, labels_train, labels_test = train_test_split(images, labels,\n",
    "                                                                  test_size=0.25,\n",
    "                                                                  random_state=1,\n",
    "                                                                  stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(file=\"/data/joint_scoring/img_train.npy\", arr=img_train)\n",
    "np.save(file=\"/data/joint_scoring/img_test.npy\", arr=img_test)\n",
    "np.save(file=\"/data/joint_scoring/labels_train.npy\", arr=labels_train)\n",
    "np.save(file=\"/data/joint_scoring/labels_test.npy\", arr=labels_test)\n",
    "\n",
    "#np.save(file=\"/Users/janickrohrbach/Desktop/joint_scoring/img_train.npy\", arr=img_train)\n",
    "#np.save(file=\"/Users/janickrohrbach/Desktop/joint_scoring/img_test.npy\", arr=img_test)\n",
    "#np.save(file=\"/Users/janickrohrbach/Desktop/joint_scoring/labels_train.npy\", arr=labels_train)\n",
    "#np.save(file=\"/Users/janickrohrbach/Desktop/joint_scoring/labels_test.npy\", arr=labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_train = np.load(file=\"/data/joint_scoring/img_train.npy\")\n",
    "img_test = np.load(file=\"/data/joint_scoring/img_test.npy\")\n",
    "labels_train = np.load(file=\"/data/joint_scoring/labels_train.npy\")\n",
    "labels_test = np.load(file=\"/data/joint_scoring/labels_test.npy\")\n",
    "\n",
    "#img_train = np.load(file=\"/Users/janickrohrbach/Desktop/joint_scoring/img_train.npy\")\n",
    "#img_test = np.load(file=\"/Users/janickrohrbach/Desktop/joint_scoring/img_test.npy\")\n",
    "#labels_train = np.load(file=\"/Users/janickrohrbach/Desktop/joint_scoring/labels_train.npy\")\n",
    "#labels_test = np.load(file=\"/Users/janickrohrbach/Desktop/joint_scoring/labels_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# one hot encode outputs\n",
    "labels_train = LabelBinarizer().fit_transform(labels_train)\n",
    "labels_test = LabelBinarizer().fit_transform(labels_test)\n",
    "num_classes = labels_test.shape[1]\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", input_shape=(150, 150, 1),\n",
    "                     activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=256, kernel_initializer=\"he_normal\",\n",
    "                    activation=\"relu\"))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Dense(units=256, kernel_initializer=\"he_normal\",\n",
    "                    activation=\"relu\"))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Dense(units=num_classes, activation=\"softmax\",\n",
    "                    kernel_initializer=\"he_normal\"))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 150, 150, 32)      320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 150, 150, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 75, 75, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 75, 75, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 37, 37, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 37, 37, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 18, 18, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 18, 18, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 9, 9, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 4, 4, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 872,100\n",
      "Trainable params: 872,100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = conv_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard callback\n",
    "tb_callback = callbacks.TensorBoard(log_dir=\"/data/joint_scoring/tensorboard/2nd_model\",\n",
    "                                    histogram_freq=0, write_graph=True,\n",
    "                                    write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 75413 samples, validate on 25138 samples\n",
      "Epoch 1/20\n",
      "100s - loss: 0.1368 - acc: 0.9569 - val_loss: 0.1433 - val_acc: 0.9565\n",
      "Epoch 2/20\n",
      "98s - loss: 0.1359 - acc: 0.9580 - val_loss: 0.1375 - val_acc: 0.9576\n",
      "Epoch 3/20\n",
      "98s - loss: 0.1316 - acc: 0.9582 - val_loss: 0.1432 - val_acc: 0.9582\n",
      "Epoch 4/20\n",
      "98s - loss: 0.1274 - acc: 0.9589 - val_loss: 0.1422 - val_acc: 0.9552\n",
      "Epoch 5/20\n",
      "98s - loss: 0.1269 - acc: 0.9587 - val_loss: 0.1548 - val_acc: 0.9591\n",
      "Epoch 6/20\n",
      "98s - loss: 0.1237 - acc: 0.9596 - val_loss: 0.1358 - val_acc: 0.9580\n",
      "Epoch 7/20\n",
      "98s - loss: 0.1191 - acc: 0.9606 - val_loss: 0.1439 - val_acc: 0.9560\n",
      "Epoch 8/20\n",
      "98s - loss: 0.1192 - acc: 0.9606 - val_loss: 0.1408 - val_acc: 0.9572\n",
      "Epoch 9/20\n",
      "97s - loss: 0.1155 - acc: 0.9610 - val_loss: 0.1446 - val_acc: 0.9556\n",
      "Epoch 10/20\n",
      "97s - loss: 0.1149 - acc: 0.9614 - val_loss: 0.1605 - val_acc: 0.9582\n",
      "Epoch 11/20\n",
      "97s - loss: 0.1109 - acc: 0.9623 - val_loss: 0.1600 - val_acc: 0.9564\n",
      "Epoch 12/20\n",
      "97s - loss: 0.1094 - acc: 0.9627 - val_loss: 0.1676 - val_acc: 0.9578\n",
      "Epoch 13/20\n",
      "97s - loss: 0.1085 - acc: 0.9626 - val_loss: 0.1543 - val_acc: 0.9582\n",
      "Epoch 14/20\n",
      "97s - loss: 0.1300 - acc: 0.9596 - val_loss: 0.1584 - val_acc: 0.9570\n",
      "Epoch 15/20\n",
      "97s - loss: 0.1067 - acc: 0.9628 - val_loss: 0.1535 - val_acc: 0.9572\n",
      "Epoch 16/20\n",
      "97s - loss: 0.1045 - acc: 0.9635 - val_loss: 0.1431 - val_acc: 0.9560\n",
      "Epoch 17/20\n",
      "97s - loss: 0.1030 - acc: 0.9636 - val_loss: 0.1583 - val_acc: 0.9576\n",
      "Epoch 18/20\n",
      "97s - loss: 0.0989 - acc: 0.9648 - val_loss: 0.1541 - val_acc: 0.9563\n",
      "Epoch 19/20\n",
      "97s - loss: 0.0972 - acc: 0.9659 - val_loss: 0.1566 - val_acc: 0.9572\n",
      "Epoch 20/20\n",
      "97s - loss: 0.0983 - acc: 0.9656 - val_loss: 0.1539 - val_acc: 0.9581\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.contrib.keras.python.keras.callbacks.History at 0x7f96301a3518>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(x=img_train, y=labels_train, batch_size=100, epochs=20, verbose=2,\n",
    "          callbacks=[tb_callback], validation_data=(img_test, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 4.19%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(img_test, labels_test, verbose=0)\n",
    "print(\"Error: %.2f%%\" % (100 - scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('/data/joint_scoring/2nd_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
